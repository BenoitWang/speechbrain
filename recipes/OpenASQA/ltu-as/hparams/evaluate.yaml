# ################################
# Model: Whisper + TLTR + Audio_Proj + LLaMa3
# Authors: Yingzhi Wang 2024
# ################################
output_folder: results/with_llama3-evaluate
eval_log: !ref <output_folder>/eval_log.txt
# LLAMA3 tokenizer
cutoff_len: 200

inference_folder: !PLACEHOLDER # please make up an inference folder same as the huggingface repo
# URL for the LLAMA3 model and its save folder
llama_hub: meta-llama/Meta-Llama-3-8B-Instruct
llama3_folder: !PLACEHOLDER # same as the llama3 folder of stage 1

# URL for another llm model for audio classification, make sure enough num of gpus are allowed when using a large model
external_llm: meta-llama/Meta-Llama-3-70B-Instruct

# evaluation annotations
eval_esc50_json: !PLACEHOLDER # /path/to/results/with_llama3-stage0/1995/eval_esc50.json
eval_iemocap_emo_json: !PLACEHOLDER # /path/to/results/with_llama3-stage0/1995/eval_iemocap_emo.json
eval_voxceleb_gender_json: !PLACEHOLDER # /path/to/results/with_llama3-stage0/1995/eval_voxceleb_gender.json
eval_voxceleb_age_json: !PLACEHOLDER # /path/to/results/with_llama3-stage0/1995/eval_voxceleb_age.json
eval_librispeech_asr_json: !PLACEHOLDER # /path/to/results/with_llama3-stage0/1995/eval_librispeech_asr.json
